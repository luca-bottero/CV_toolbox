{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection import keypointrcnn_resnet50_fpn, KeypointRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.transforms import transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision.utils import draw_keypoints\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# pairs of edges for 17 of the keypoints detected ...\n",
    "# ... these show which points to be connected to which point ...\n",
    "# ... we can omit any of the connecting points if we want, basically ...\n",
    "# ... we can easily connect less than or equal to 17 pairs of points ...\n",
    "# ... for keypoint RCNN, not  mandatory to join all 17 keypoint pairs\n",
    "edges = [\n",
    "    (0, 1), (0, 2), (2, 4), (1, 3), (6, 8), (8, 10),\n",
    "    (5, 7), (7, 9), (5, 11), (11, 13), (13, 15), (6, 12),\n",
    "    (12, 14), (14, 16), (5, 6)\n",
    "]\n",
    "\n",
    "def draw_keypoints_and_boxes(outputs, image):\n",
    "    # the `outputs` is list which in-turn contains the dictionary \n",
    "    for i in range(len(outputs[0]['keypoints'])):\n",
    "        # get the detected keypoints\n",
    "        keypoints = outputs[0]['keypoints'][i].cpu().detach().numpy()\n",
    "        # get the detected bounding boxes\n",
    "        boxes = outputs[0]['boxes'][i].cpu().detach().numpy()\n",
    "\n",
    "        # proceed to draw the lines and bounding boxes \n",
    "        if outputs[0]['scores'][i] > 0.9: # proceed if confidence is above 0.9\n",
    "            keypoints = keypoints[:, :].reshape(-1, 3)\n",
    "            for p in range(keypoints.shape[0]):\n",
    "                # draw the keypoints\n",
    "                cv2.circle(image, (int(keypoints[p, 0]), int(keypoints[p, 1])), \n",
    "                            3, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            # draw the lines joining the keypoints\n",
    "            for ie, e in enumerate(edges):\n",
    "                # get different colors for the edges\n",
    "                rgb = matplotlib.colors.hsv_to_rgb([\n",
    "                    ie/float(len(edges)), 1.0, 1.0\n",
    "                ])\n",
    "                rgb = rgb*255\n",
    "                # join the keypoint pairs to draw the skeletal structure\n",
    "                cv2.line(image, (int(keypoints[e, 0][0]), int(keypoints[e, 1][0])),\n",
    "                        (int(keypoints[e, 0][1]), int(keypoints[e, 1][1])),\n",
    "                        tuple(rgb), 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "            # draw the bounding boxes around the objects\n",
    "            cv2.rectangle(image, (int(boxes[0]), int(boxes[1])), (int(boxes[2]), int(boxes[3])),\n",
    "                          color=(0, 255, 0), \n",
    "                          thickness=2)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cont = 0\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor() \n",
    "])\n",
    "\n",
    "\n",
    "def get_model(min_size=800):\n",
    "    # initialize the model\n",
    "    model = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=True,\n",
    "                                                                   num_keypoints=17, \n",
    "                                                                   min_size=min_size)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model().to(device).eval()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()     #ret is a flag that indicates if the frame has been captured\n",
    "    frame = cv2.resize(frame, None, fx=1., fy=1., interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    pil_image = Image.fromarray(frame).convert('RGB')\n",
    "    image = transform(pil_image)\n",
    "    image.unsqueeze(0).to(device)\n",
    "    outputs = model([image])\n",
    "    output_image = draw_keypoints_and_boxes(outputs, frame)\n",
    "\n",
    "    cv2.putText(frame, \"OpenCV - press ESC to exit\", (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Input', output_image)\n",
    "\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break       #27 is ascii for ESC\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
